#!/bin/bash
#
#SBATCH --partition=standard
#SBATCH --account=t3
#SBATCH --job-name=extract_TTTo2L2Nu
#SBATCH --mem=60000M
#SBATCH --nodes=1
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=8
#SBATCH --time 02:00:00
#SBATCH -o %x-%j.out    # replace default slurm-SLURM_JOB_ID.out; %x is a job-name (or script name when there is no job-name)
#SBATCH -e %x-%j.err    # replace default slurm-SLURM_JOB_ID.err

cd /work/phummler/code/

echo start: $(date)
echo HOME: $HOME
echo USER: $USER
echo SLURM_JOB_ID: $SLURM_JOB_ID
echo HOSTNAME: $HOSTNAME
echo pwd: $(pwd)
echo CUDA_VISIBLE_DEVICES: $CUDA_VISIBLE_DEVICES

# each worker node has local /scratch space to be used during job run
mkdir -p /scratch/$USER/${SLURM_JOB_ID}
export TMPDIR=/scratch/$USER/${SLURM_JOB_ID}

# here comes a computation
/work/phummler/miniconda3/envs/master_thesis/bin/python /work/phummler/code/main.py extract --dataset=TTTo2L2Nu
# cleaning of temporal working dir when job was completed:
rm -rf /scratch/$USER/${SLURM_JOB_ID}

echo end: $(date)
